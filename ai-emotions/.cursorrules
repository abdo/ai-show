# AI Show - Project Rules & Architecture

## Project Overview

**AI Show** is a React + TypeScript web application that creates cinematic, AI-generated conversations from user situations. It uses:
- **Groq AI** (`llama-3.3-70b-versatile`) for generating dramatic character dialogues
- **OpenAI TTS** (`gpt-4o-mini-tts`) for realistic, persona-based voice generation
- **React 18 + Vite** for fast development and modern tooling

The app generates 3-6 distinct characters with unique voices, personalities, and perspectives, then plays their conversation as an animated theatrical experience.

---

## Tech Stack

### Core
- **Build Tool**: Vite
- **Language**: TypeScript (strict mode)
- **UI Framework**: React 18 (functional components only)
- **Styling**: CSS Modules / Plain CSS
- **Animation**: GSAP (for ChromaGrid)
- **HTTP Client**: Axios

### AI Services
- **Text Generation**: Groq API (`llama-3.3-70b-versatile`)
- **Voice Synthesis**: OpenAI TTS API (`gpt-4o-mini-tts`)

### Key Libraries
- `ogl` - WebGL graphics (for backgrounds)
- `gsap` - Smooth animations

---

## Architecture

### File Structure

```
src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ ChromaGrid.tsx           # Interactive character grid with spotlight effect
‚îÇ   ‚îú‚îÄ‚îÄ ChromaGrid.css
‚îÇ   ‚îú‚îÄ‚îÄ LandingPage/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ LandingPage.tsx      # Hero + input section
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ LandingPage.css
‚îÇ   ‚îî‚îÄ‚îÄ [PascalCase components]
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îú‚îÄ‚îÄ usePerspectives.ts       # Groq AI story generation
‚îÇ   ‚îî‚îÄ‚îÄ usePersonaVoices.ts      # OpenAI TTS voice management
‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îú‚îÄ‚îÄ avatarConstants.ts       # Gender-specific avatar pools
‚îÇ   ‚îî‚îÄ‚îÄ [utility files]
‚îú‚îÄ‚îÄ assets/
‚îÇ   ‚îî‚îÄ‚îÄ theatre.webp             # Landing page background
‚îú‚îÄ‚îÄ keys.ignore.ts               # API keys (never commit!)
‚îú‚îÄ‚îÄ App.tsx                      # Main app orchestration
‚îî‚îÄ‚îÄ main.tsx                     # Entry point
```

### Component Hierarchy

```
App
‚îú‚îÄ‚îÄ LandingPage (when !hasSubmitted)
‚îÇ   ‚îî‚îÄ‚îÄ Theatre spotlight effect
‚îî‚îÄ‚îÄ ChromaGrid + Dialogue Player (when hasSubmitted)
    ‚îî‚îÄ‚îÄ Animated character cards with voices
```

---

## Key Concepts

### 1. Story Generation Flow

1. User enters a situation (e.g., "My partner wants kids but I'm not sure")
2. `usePerspectives` sends to Groq AI with detailed prompt
3. AI returns 3-6 characters with:
   - Name, gender, role (from 20 standardized roles)
   - Border colors and gradients
   - 14-18 dialogue lines
4. Characters get:
   - Gender-appropriate avatars (from `pravatarImgIdsForMales/Females`)
   - Gender-appropriate OpenAI voices (never repeated if possible)
   - Role-based TTS instructions

### 2. Voice System

**20 Standardized Roles** (defined in `usePersonaVoices.ts`):
- empathetic, analytical, provocateur, emotional, calm, assertive, skeptical, optimistic, cynical, nurturing, intense, playful, serious, wise, rebellious, mediator, challenger, supporter, observer, wildcard

Each role maps to:
- **Instructions** for OpenAI TTS (e.g., "raw, expressive, passionate")
- **Voice pool** by gender (males: onyx, ash, echo; females: alloy, nova, shimmer, sage, coral)

**Voice Selection Logic**:
- Tracks `usedVoices` Set per story generation
- Picks from unused voices first (to avoid repetition)
- Falls back to random if all voices exhausted
- Male characters: 3 voices (can repeat after 3 males)
- Female characters: 5 voices (can repeat after 5 females)

### 3. Text-to-Speech Pipeline

1. User clicks "Play the conversation"
2. Browser requests user interaction (autoplay policy bypass)
3. `usePersonaVoices` generates all voices in parallel:
   - Cleans text (removes markdown, emojis, stage directions)
   - Calls OpenAI TTS with role-based instructions
   - Converts response to base64 `data:audio/mp3` URI
4. Plays dialogue sequentially with 100ms delay on first audio (prevents cutoff)
5. Highlights speaking character in ChromaGrid

---

## Coding Standards

### TypeScript

- **No `any`** - use `unknown` or proper types
- **Explicit prop types** for all components
- **Named exports** preferred (except main component per file)
- **Type imports** when appropriate (`import type { ... }`)

Example:
```typescript
type CharacterCardProps = {
  name: string;
  role: CharacterRole;
  onSelect?: (id: string) => void;
};

export function CharacterCard({ name, role, onSelect }: CharacterCardProps) {
  // ...
}
```

### React Patterns

- **Functional components only** (no classes)
- **Hooks**: `useState`, `useEffect`, `useCallback`, `useMemo`, `useRef`
- **Custom hooks** for complex logic (data fetching, voice management)
- **Controlled components** for forms
- **Context** for deep prop drilling (not global state)

### State Management

- **React hooks** for local state
- **useMemo** for expensive computations
- **useCallback** for stable function references
- **useRef** for mutable values that don't trigger re-renders

### Async Patterns

Always handle:
- ‚úÖ Loading states (`isLoading`)
- ‚úÖ Error states (`error`)
- ‚úÖ Success states (`data`)
- ‚úÖ Cleanup (abort controllers, unmount flags)

Example:
```typescript
const [state, setState] = useState({ data: null, isLoading: false, error: null });

useEffect(() => {
  let isMounted = true;
  
  async function fetch() {
    setState(prev => ({ ...prev, isLoading: true }));
    try {
      const result = await apiCall();
      if (isMounted) setState({ data: result, isLoading: false, error: null });
    } catch (error) {
      if (isMounted) setState({ data: null, isLoading: false, error: error.message });
    }
  }
  
  fetch();
  return () => { isMounted = false; };
}, []);
```

### Styling

- **CSS files** co-located with components
- **BEM-like naming** or component-scoped classes
- **CSS custom properties** for theming (e.g., `--angle` for animations)
- **Responsive**: use `clamp()`, `vw`, media queries
- **Dark theme**: base is `#000`, use rgba for overlays

### Performance

- **Lazy load** heavy components if needed
- **Memoize** expensive computations
- **Debounce** user input where appropriate
- **Virtual scrolling** for large lists (if needed)
- **Parallel API calls** when independent (e.g., voice generation)

---

## API Keys & Security

### Keys Location: `src/keys.ignore.ts`

```typescript
export const groqApiKey = "gsk_...";
export const openAiTTSApiKey = "sk-proj-...";
```

**Rules**:
- ‚úÖ Never commit `keys.ignore.ts` (in `.gitignore`)
- ‚úÖ Never log keys to console
- ‚úÖ Client-side keys only (no server secrets)
- ‚úÖ Use environment variables in production

---

## AI Prompts

### Groq Story Generation (`usePerspectives.ts`)

**Prompt Structure**:
1. **Mission**: Create gripping, emotionally charged conversation
2. **Character Depth**: Distinct styles, motivations, flaws
3. **Standardized Roles**: MUST use one of 20 roles (affects voice)
4. **Conversation Dynamics**: 20 narrative techniques (e.g., "bold opening", "heated exchange")
5. **Act Structure**: 
   - Act 1 (4-5 lines): Hook + establish characters
   - Act 2 (6-8 lines): Escalate conflict + reveal layers
   - Act 3 (4-5 lines): Climax + transformation
6. **Dialogue Craft**: Contractions, fragments, stage directions, natural cadence
7. **Forbidden**: Therapist-speak, tidy resolutions, exposition

**Output**: JSON with `characters[]` and `dialogue[]`

### OpenAI TTS Instructions (`usePersonaVoices.ts`)

Each role has concise instructions (e.g., "warm, understanding, slower speech" for empathetic). These are dynamically passed to `gpt-4o-mini-tts` to shape voice characteristics.

---

## Common Patterns

### Adding a New Character Role

1. Add to `availableRoles` in `usePersonaVoices.ts`
2. Add description to `roleDescriptions` object
3. `roleVoiceConfigs` auto-generates from descriptions
4. No need to update Groq prompt (it's dynamic)

### Adding a New Voice

1. Verify voice is supported by OpenAI TTS
2. Add to `maleVoices` or `femaleVoices` in `usePerspectives.ts`
3. Test with `test-openai-voices.html` (standalone test page)

### Debugging Voice Issues

- Check console for `[Voice N] CharacterName (gender, role): voice=X, model=Y`
- Verify base64 audio URI is generated (`data:audio/mp3;base64,...`)
- Check browser autoplay policy (requires user interaction first)
- Inspect OpenAI API response status (401 = permissions, 429 = rate limit)

### Text Cleaning for TTS

Located in `usePersonaVoices.ts` (`cleanTextForTTS` function):
- Removes markdown (`**bold**`, `_italic_`)
- Removes emojis (üé≠, ‚ù§Ô∏è, etc.)
- Removes stage directions (`[pauses]`, `[laughs]`)
- Preserves punctuation for natural pauses

---

## Testing

### Browser Testing
- Always test with user interaction (click to play)
- Test on Chrome, Firefox, Safari (autoplay policies differ)
- Test with network throttling (for loading states)

### Manual Test Scenarios
1. Generate story with 3 characters (all unique voices)
2. Generate story with 6 characters (some voice repetition expected)
3. Generate story with all male/all female characters
4. Test first audio cutoff fix (100ms delay)
5. Test character highlighting during speech

---

## Known Limitations

1. **Voice Repetition**: After 3 males or 5 females, voices will repeat
2. **Browser Autoplay**: First interaction required to unlock audio
3. **Rate Limits**: OpenAI TTS has rate limits (429 errors possible)
4. **Mobile**: Spotlight animation may be heavy on low-end devices

---

## Future Improvements (Potential)

- [ ] User authentication & saved stories
- [ ] Custom voice selection per character
- [ ] Export conversation as audio file
- [ ] More visual themes (not just theatre)
- [ ] Multi-language support
- [ ] Character emotion visualization (beyond highlighting)

---

## Development Workflow

### Starting Dev Server
```bash
npm install
npm run dev
```

### Building for Production
```bash
npm run build
npm run preview  # Test production build
```

### Code Quality
- Run linter before committing
- Fix all TypeScript errors (no `@ts-ignore`)
- Test in browser (not just CLI)

---

## Troubleshooting

### "Cannot read properties of undefined (reading 'has')"
- `usedVoices` Set not passed to `getRandomVoice`
- Check `fetchStory` in `usePerspectives.ts`

### "401 Unauthorized" from OpenAI
- API key missing or invalid permissions
- Ensure key has "model.request" scope

### "Audio cutoff at start"
- First audio needs 100ms delay (`isFirstAudio` flag)
- Check `playDialogue` in `usePersonaVoices.ts`

### "Characters don't highlight when speaking"
- `currentDialogueIndex` not updating
- Check `setCurrentDialogueIndex` in `playDialogue`

---

## Important Files

| File | Purpose | Don't Touch |
|------|---------|-------------|
| `keys.ignore.ts` | API keys | Never commit |
| `usePerspectives.ts` | Core AI logic | Prompt is carefully tuned |
| `usePersonaVoices.ts` | Voice engine | Role system is standardized |
| `avatarConstants.ts` | Avatar pools | Gender-specific IDs |
| `ChromaGrid.tsx` | Visual engine | GSAP animations are delicate |

---

## Quick Reference

### Character Roles (20)
empathetic, analytical, provocateur, emotional, calm, assertive, skeptical, optimistic, cynical, nurturing, intense, playful, serious, wise, rebellious, mediator, challenger, supporter, observer, wildcard

### Male Voices (3)
onyx, ash, echo

### Female Voices (5)
alloy, nova, shimmer, sage, coral

### Key Hooks
- `usePerspectives()` - Story generation
- `usePersonaVoices(story, unlocked)` - Voice management

### Key Components
- `LandingPage` - Hero + input
- `ChromaGrid` - Character grid
- `App` - Orchestration

---

**Last Updated**: November 2024
**Maintainer**: AI Show Team
**License**: [Your License]
